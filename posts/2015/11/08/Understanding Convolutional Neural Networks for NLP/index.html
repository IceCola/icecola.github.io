<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Understanding Convolutional Neural Networks for NLP | Ola</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="When we hear about Convolutional Neural Network (CNNs), we typically think of Computer Vision. CNNs were responsible for major breakthroughs in Image Classification and are the core of most Computer V">
<meta property="og:type" content="article">
<meta property="og:title" content="Understanding Convolutional Neural Networks for NLP">
<meta property="og:url" content="http://yoursite.com/posts/2015/11/08/Understanding Convolutional Neural Networks for NLP/index.html">
<meta property="og:site_name" content="Ola">
<meta property="og:description" content="When we hear about Convolutional Neural Network (CNNs), we typically think of Computer Vision. CNNs were responsible for major breakthroughs in Image Classification and are the core of most Computer V">
<meta property="og:image" content="http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg">
<meta property="og:image" content="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM-1024x937.png">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png">
<meta property="og:image" content="http://s0.wp.com/latex.php?zoom=3&latex=n_%7Bout%7D%3D%28n_%7Bin%7D+%2B+2%2An_%7Bpadding%7D+-+n_%7Bfilter%7D%29+%2B+1+&bg=ffffff&fg=000&s=0">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM-1024x251.png">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png">
<meta property="og:image" content="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png">
<meta property="og:updated_time" content="2015-11-08T11:15:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Understanding Convolutional Neural Networks for NLP">
<meta name="twitter:description" content="When we hear about Convolutional Neural Network (CNNs), we typically think of Computer Vision. CNNs were responsible for major breakthroughs in Image Classification and are the core of most Computer V">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Ola</a></h1>
		</hgroup>

		
		<p class="header-subtitle">火力全開</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">首页</a></li>
				        
							<li><a href="/archives">归档</a></li>
				        
							<li><a href="/categories/Coding">编程</a></li>
				        
							<li><a href="/tags/Java">Java</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/JDBC/" style="font-size: 10px;">JDBC</a> <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/Javascript/" style="font-size: 10px;">Javascript</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/OS-X/" style="font-size: 10px;">OS X</a> <a href="/tags/Octopress/" style="font-size: 10px;">Octopress</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/单例/" style="font-size: 10px;">单例</a> <a href="/tags/卷积神经网络/" style="font-size: 10px;">卷积神经网络</a> <a href="/tags/后台开发/" style="font-size: 10px;">后台开发</a> <a href="/tags/环境配置/" style="font-size: 10px;">环境配置</a> <a href="/tags/线程同步/" style="font-size: 10px;">线程同步</a> <a href="/tags/设计模式/" style="font-size: 10px;">设计模式</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">我们‘记得’过去,但和这个‘过去’相逢时却对面不识。思想总在回溯,但是时光一直前行,一旦分离,即是永诀。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Ola</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/avatar.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Ola</h1>
			</hgroup>
			
			<p class="header-subtitle">火力全開</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">首页</a></li>
		        
					<li><a href="/archives">归档</a></li>
		        
					<li><a href="/categories/Coding">编程</a></li>
		        
					<li><a href="/tags/Java">Java</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Understanding Convolutional Neural Networks for NLP" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/posts/2015/11/08/Understanding Convolutional Neural Networks for NLP/" class="article-date">
  	<time datetime="2015-11-08T02:16:34.000Z" itemprop="datePublished">2015-11-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Understanding Convolutional Neural Networks for NLP
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/">NLP</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积神经网络/">卷积神经网络</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/机器学习/">机器学习</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>When we hear about Convolutional Neural Network (CNNs), we typically think of Computer Vision. CNNs were responsible for major breakthroughs in Image Classification and are the core of most Computer Vision systems today, from Facebook’s automated photo tagging to self-driving cars.</p>
<p>More recently we’ve also started to apply CNNs to problems in Natural Language Processing and gotten some interesting results. In this post I’ll try to summarize what CNNs are, and how they’re used in NLP. The intuitions behind CNNs are somewhat easier to understand for the Computer Vision use case, so I’ll start there, and then slowly move towards NLP.</p>
<h3 id="What_is_Convolution?">What is Convolution?</h3><p>The for me easiest way to understand a convolution is by thinking of it as a sliding window function applied to a matrix. That’s a mouthful, but it becomes quite clear looking at a visualization:</p>
<p><img src="http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif" alt="Convolution with 3×3 Filter"></p>
<font size="2">Convolution with 3×3 Filter. Source: <a href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" target="_blank" rel="external">http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution</a></font>

<p>Imagine that the matrix on the left represents an black and white image. Each entry corresponds to one pixel, 0 for black and 1 for white (typically it’s between 0 and 255 for grayscale images). The sliding window is called a kernel, filter, or feature detector. Here we use a 3×3 filter, multiply its values element-wise with the original matrix, then sum them up. To get the full convolution we do this for each element by sliding the filter over the whole matrix.</p>
<p>You may be wondering wonder what you can actually do with this. Here are some intuitive examples.</p>
<a id="more"></a>
<h4 id="Averaging_each_pixel_with_its_neighboring_values_blurs_an_image:">Averaging each pixel with its neighboring values blurs an image:</h4><p> <img src="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-blur.jpg" alt=""></p>
<h4 id="Taking_the_difference_between_a_pixel_and_its_neighbors_detects_edges:">Taking the difference between a pixel and its neighbors detects edges:</h4><p>(To understand this one intuitively, think about what happens in parts of the image that are smooth, where a pixel color equals that of its neighbors: The additions cancel and the resulting value is 0, or black. If there’s a sharp edge in intensity, a transition from white to black for example, you get a large difference and a resulting white value)</p>
<p><img src="http://docs.gimp.org/en/images/filters/examples/generic-taj-convmatrix-edge-detect.jpg" alt=""> </p>
<p>The <a href="http://docs.gimp.org/en/plug-in-convmatrix.html" target="_blank" rel="external">GIMP manual</a> has a few other examples. To understand more about how convolutions work I also recommend checking out <a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/" target="_blank" rel="external">Chris Olah’s post on the topic</a>.</p>
<h3 id="What_are_Convolutional_Neural_Networks?">What are Convolutional Neural Networks?</h3><p>Now you know what convolutions are. But what about CNNs? CNNs are basically just several layers of convolutions with nonlinear activation functions like <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks" target="_blank" rel="external">ReLU</a>) or <a href="https://reference.wolfram.com/language/ref/Tanh.html" target="_blank" rel="external">tanh</a> applied to the results. In a traditional feedforward neural network we connect each input neuron to each output neuron in the next layer. That’s also called a fully connected layer, or affine layer. In CNNs we don’t do that. Instead, we use convolutions over the input layer to compute the output. This results in local connections, where each region of the input is connected to a neuron in the output. Each layer applies different filters, typically hundreds or thousands like the ones showed above, and combines their results. There’s also something something called pooling (subsampling) layers, but I’ll get into that later. During the training phase, <strong>a CNN automatically learns the values of its filters</strong> based on the task you want to perform. For example, in Image Classification a CNN may learn to detect edges from raw pixels in the first layer, then use the edges to detect simple shapes in the second layer, and then use these shapes to deter higher-level features, such as facial shapes in higher layers. The last layer is then a classifier that uses these high-level features.</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-07-at-7.26.20-AM.png" alt="Convolutional Neural Network (Clarifai)"></p>
<p>There are two aspects of this computation worth paying attention to: <strong>Location Invariance</strong> and <strong>Compositionality</strong>. Let’s say you want to classify whether or not there’s an elephant in an image. Because you are sliding your filters over the whole image you don’t really care where the elephant occurs. In practice,  pooling also gives you invariance to translation, rotation and scaling, but more on that later. The second key aspect is (local) compositionality. Each filter composes a local patch of lower-level features into higher-level representation. That’s why CNNs are so powerful in Computer Vision. It makes intuitive sense that you build edges from pixels, shapes from edges, and more complex objects from shapes.</p>
<h4 id="So,_how_does_any_of_this_apply_to_NLP?">So, how does any of this apply to NLP?</h4><p>Instead of image pixels, the input to most NLP tasks are sentences or documents represented as a matrix. Each row of the matrix corresponds to one token, typically a word, but it could be a character. That is, each row is vector that represents a word. Typically, these vectors are word embeddings (low-dimensional representations) like <a href="https://code.google.com/p/word2vec/" target="_blank" rel="external">word2vec</a> or <a href="http://nlp.stanford.edu/projects/glove/" target="_blank" rel="external">GloVe</a>, but they could also be one-hot vectors that index the word into a vocabulary. For a 10 word sentence using a 100-dimensional embedding we would have a 10×100 matrix as our input. That’s our “image”.</p>
<p>In vision, our filters slide over local patches of an image, but in NLP we typically use filters that slide over full rows of the matrix (words). Thus, the “width” of our filters is usually the same as the width of the input matrix. The height, or region size, may vary, but sliding windows over 2-5 words at a time is typical. Putting all the above together, a Convolutional Neural Network for NLP may look like this (take a few minutes and try understand this picture and how the dimensions are computed. You can ignore the pooling for now, we’ll explain that later):</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-12.05.40-PM-1024x937.png" alt=""></p>
<font size="2">Illustration of a Convolutional Neural Network (CNN) architecture for sentence classification. Here we depict three filter region sizes: 2, 3 and 4, each of which has 2 filters. Every filter performs convolution on the sentence matrix and generates (variable-length) feature maps. Then 1-max pooling is performed over each map, i.e., the largest number from each feature map is recorded. Thus a univariate feature vector is generated from all six maps, and these 6 features are concatenated to form a feature vector for the penultimate layer. The final softmax layer then receives this feature vector as input and uses it to classify the sentence; here we assume binary classification and hence depict two possible output states. Source: hang, Y., &amp; Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification</font>

<p>What about the nice intuitions we had for Computer Vision? Location Invariance and local Compositionality made intuitive sense for images, but not so much for NLP. You probably do care a lot where in the sentence a word appears. Pixels close to each other are likely to be semantically related (part of the same object), but the same isn’t always true for words. In many languages, parts of phrases could be separated by several other words. The compositional aspect isn’t obvious either. Clearly, words compose in some ways, like an adjective modifying a noun, but how exactly this works what higher level representations actually “mean” isn’t as obvious as in the Computer Vision case.</p>
<p>Given all this, it seems like CNNs wouldn’t be a good fit for NLP tasks. <a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="external">Recurrent Neural Networks</a> make more intuitive sense. They resemble how we process language (or at least how we think we process language): Reading sequentially from left to right. Fortunately, this doesn’t mean that CNNs don’t work.  <a href="https://en.wikipedia.org/wiki/All_models_are_wrong" target="_blank" rel="external">All models are wrong, but some are useful</a>. It turns out that CNNs applied to NLP problems perform quite well. The simple <a href="https://en.wikipedia.org/wiki/Bag-of-words_model" target="_blank" rel="external">Bag of Words model</a> is an obvious oversimplification with incorrect assumptions, but has nonetheless been the standard approach for years and lead to pretty good results.</p>
<p>A big argument for CNNs is that they are fast. Very fast. Convolutions are a central part of computer graphics and implemented on a hardware level on GPUs. Compared to something like <a href="https://en.wikipedia.org/wiki/N-gram" target="_blank" rel="external">n-grams</a>, CNNs are also efficient in terms of representation. With a large vocabulary, computing anything more than 3-grams can quickly become expensive. Even Google doesn’t provide anything beyond 5-grams. Convolutional Filters learn good representations automatically, without needing to represent the whole vocabulary. It’s completely reasonable to have filters of size larger than 5. I like to think that many of the learned filters in the first layer are capturing features quite similar (but not limited) to n-grams, but represent them in a more compact way.</p>
<h3 id="CNN_Hyperparameters">CNN Hyperparameters</h3><p>Before explaining at how CNNs are applied to NLP tasks, let’s look at some of the choices you need to make when building a CNN. Hopefully this will help you better understand the literature in the field.</p>
<h4 id="Narrow_vs-_Wide_convolution">Narrow vs. Wide convolution</h4><p>When I explained convolutions above I neglected a little detail of how we apply the filter. Applying a 3×3 filter at the center of the matrix works fine, but what about the edges? How would you apply the filter to the first element of a matrix that doesn’t have any neighboring elements to the top and left? You can use zero-padding. All elements that would fall outside of the matrix are taken to be zero. By doing this you can apply the filter to every element of your input matrix, and get a larger or equally sized output. Adding zero-padding is also called wide convolution, and not using zero-padding would be a narrow convolution. An example in 1D looks like this:</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-9.47.41-AM.png" alt=""></p>
<font size="2">Narrow vs. Wide Convolution. Source: A Convolutional Neural Network for Modelling Sentences (2014)</font>

<p>You can see how wide convolution is useful, or even necessary, when you have a large filter relative to the input size. In the above, the narrow convolution yields  an output of size (7-5) + 1 = 3, and a wide convolution an output of size (7+ 2* 4-5)+1 = 11 . More generally, the formula for the output size is:<br><img src="http://s0.wp.com/latex.php?zoom=3&amp;latex=n_%7Bout%7D%3D%28n_%7Bin%7D+%2B+2%2An_%7Bpadding%7D+-+n_%7Bfilter%7D%29+%2B+1+&amp;bg=ffffff&amp;fg=000&amp;s=0" alt=""></p>
<h4 id="Stride_Size">Stride Size</h4><p>Another hyperparameter for your convolutions is the stride size, defining by how much you want to shift your filter at each step.  In all the examples above the stride size was 1, and consecutive applications of the filter overlapped. A larger stride size leads to fewer applications of the filter and a smaller output size. The following from the <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">Stanford cs231 website</a> shows stride sizes of 1 and 2 applied to a one-dimensional input:</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-10.18.08-AM-1024x251.png" alt=""></p>
<font size="2">Convolution Stride Size. Left: Stride size 1. Right: Stride size 2. Source: <a href="http://cs231n.github.io/convolutional-networks/" target="_blank" rel="external">http://cs231n.github.io/convolutional-networks/</a></font>

<p>In the literature we typically see stride sizes of 1, but a larger stride size may allow you to build a model that behaves somewhat similarly to a <a href="https://en.wikipedia.org/wiki/Recursive_neural_network" target="_blank" rel="external">Recursive Neural Network</a>, i.e. looks like a tree.</p>
<h4 id="Pooling_Layers">Pooling Layers</h4><p>A key aspect of Convolutional Neural Networks are pooling layers, typically applied after the convolutional layers. Pooling layers subsample their input. The most common way to do pooling it to apply a max operation to the result of each filter. You don’t necessarily need to pool over the complete matrix, you could also pool over a window. For example, the following shows max pooling for a 2×2 window (in NLP we typically are apply pooling over the complete output, yielding just a single number for each filter):</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-05-at-2.18.38-PM.png" alt=""></p>
<font size="2">Max pooling in CNN. Source: <a href="http://cs231n.github.io/convolutional-networks/#pool" target="_blank" rel="external">http://cs231n.github.io/convolutional-networks/#pool</a></font>

<p>Why pooling? There are a couple of reasons. One property of pooling is that it provides a fixed size output matrix, which typically is required for classification. For example, if you have 1,000 filters and you apply max pooling to each, you will get a 1000-dimensional output, regardless of the size of your filters, or the size of your input. This allows you to use variable size sentences, and variable size filters, but always get the same output dimensions to feed into a classifier.</p>
<p>Pooling also reduces the output dimensionality but (hopefully) keeps the most salient information. You can think of each filter as detecting a specific feature, such as detecting if the sentence contains a negation like “not amazing” for example. If this phrase occurs somewhere in the sentence, the result of applying the filter to that region will yield a large value, but a small value in other regions. By performing the max operation you  are keeping information about whether or not the feature appeared in the sentence, but you are losing information about where exactly it appeared. But isn’t this information about locality really useful? Yes, it  is and it’s a bit similar to what a bag of n-grams model is doing. You are losing global information about locality (where in a sentence something happens), but you are keeping local information captured by your filters, like “not amazing” being very different from “amazing not”.</p>
<p>In imagine recognition, pooling also provides basic invariance to translating (shifting) and rotation. When you are pooling over a region, the output will stay approximately the same even if you shift/rotate the image by a few pixels, because the max operations will pick out the same value regardless.</p>
<h4 id="Channels">Channels</h4><p>The last concept we need to understand are channels. Channels are different “views” of your input data. For example, in image recognition you typically have RGB (red, green, blue) channels. You can apply convolutions across channels, either with different or equal weights. In NLP you could imagine having various channels as well: You could have a separate channels for different word embeddings (word2vec and GloVe for example), or you could have a channel for the same sentence represented in different languages, or phrased in different ways.</p>
<h3 id="Convoltuonal_Neural_Networks_applied_to_NLP">Convoltuonal Neural Networks applied to NLP</h3><p>Let’s now look at some of the applications of CNNs to Natural Language Processing. I’ll try it summarize some of the research results. Invariably I’ll miss many interesting applications (do let me know in the comments), but I hope to cover at least some of the more popular results.</p>
<p>The most natural fit for CNNs seem to be classifications tasks, such as Sentiment Analysis, Spam Detection or Topic Categorization. Convolutions and pooling operations lose information about the local order of words, so that sequence tagging as in PoS Tagging or Entity Extraction is a bit harder to fit into a pure CNN architecture (though not impossible, you can add positional features to the input).</p>
<p>[1] Evaluates a CNN architecture on various classification datasets, mostly comprised of Sentiment Analysis and Topic Categorization tasks. The CNN architecture achieves very good performance across datasets, and new state-of-the-art on a few. Surprisingly, the network used in this paper is quite simple, and that’s what makes it powerful.The input layer is a sentence comprised of concatenated word2vec word embeddings. That’s followed by a convolutional layer with multiple filters, then a max-pooling layer, and finally a softmax classifier.  The paper also experiments with two different channels in the form of static and dynamic word embeddings, where one channel is adjusted during training and the other isn’t. A similar, but somewhat more complex, architecture was previously proposed in [2]. [6] Adds an additional layer that performs “semantic clustering” to this network architecture.</p>
<p><img src="http://www.wildml.com/wp-content/uploads/2015/11/Screen-Shot-2015-11-06-at-8.03.47-AM.png" alt=""><br>Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification<br>[4] Trains a CNN from scratch, without the need for for pre-trained word vectors like word2vec or GloVe. It applies convolutions directly to one-hot vectors. The author also proposes a space-efficient bag-of-words-like representation for the input data, reducing the number of parameters the network needs to learn. In [5] the author  extends the model with an additional unsupervised “region embedding” that is learned using a CNN  predicting the context of text regions. The approach in these papers seems to work well for long-form texts (like movie reviews), but their performance on short texts (like tweets) isn’t clear. Intuitively, it makes sense that using pre-trained word embeddings for short texts would yield larger gains than using them for long texts.</p>
<p>Building a CNN architecture means that there are many hyperparameters to choose from, some of which I presented above: Input represenations (word2vec, GloVe, one-hot), number and sizes of convolution filters, pooling strategies (max, average), and activation functions (ReLU, tanh). [7] performs an empirical evaluation on the effect of varying hyperparameters in CNN architectures, investigating their impact on performance and variance over multiple runs. If you are looking to implement your own CNN for text classification, using the results of this paper as a starting point would be an excellent idea. A few results that stand out are that max-pooling always beat average pooling, that the ideal filter sizes are important but task-dependent, and that regularization doesn’t seem to make a big different in the NLP tasks that were considered. A caveat of this research is that all the datasets were quite similar in terms of their document length, so the same guidelines may not apply to data that looks considerably different.</p>
<p>[8] explores CNNs for  Relation Extraction and Relation Classification tasks. In addition to the word vectors, the authors use the relative positions of words to the entities of interest as an input to the convolutional layer. This models assumes that the positions of the entities are given, and that each example input contains one relation. [9] and [10] have explored similar models.</p>
<p>Another interesting use case of CNNs in NLP can be found in [11] and [12], coming out of Microsoft Research. These papers describe how to learn semantically meaningful representations of sentences that can be used for Information Retrieval. The example given in the papers includes recommending potentially interesting documents to users based on what they are currently reading. The sentence representations are trained based on search engine log data.</p>
<p>Most CNN architectures learn embeddings (low-dimensional representations) for words and sentences in one way or another as part of their training procedure. Not all papers though focus on this aspect of training or investigate how meaningful the learned embeddings are. [13] presents a CNN architecture to predict hashtags for Facebook posts, while at the same time generating meaningful embeddings for words and sentences. These learned embeddings are then successfully applied to another task – recommending potentially interesting documents to users, trained based on clickstream data.</p>
<p>What’s amazing is that essentially all of the papers above were published  in the past 1-2 years. Obviously there has been excellent work with CNNs on NLP before, as in <a href="http://arxiv.org/abs/1103.0398" target="_blank" rel="external">Natural Language Processing (almost) from Scratch</a>, but the pace of new results and state of the art systems being published is clearly accelerating.</p>
<h4 id="Questions_or_Feedback?_Let_me_know_in_the_comments-_Thanks_for_reading!">Questions or Feedback? Let me know in the comments. Thanks for reading!</h4><h4 id="Paper_References">Paper References</h4><p>[1] Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014), 1746–1751.<br>[2] Kalchbrenner, N., Grefenstette, E., &amp; Blunsom, P. (2014). A Convolutional Neural Network for Modelling Sentences. Acl, 655–665.<br>[3] Santos, C. N. dos, &amp; Gatti, M. (2014). Deep Convolutional Neural Networks for Sentiment Analysis of Short Texts. In COLING-2014 (pp. 69–78).<br>[4] Johnson, R., &amp; Zhang, T. (2015). Effective Use of Word Order for Text Categorization with Convolutional Neural Networks. To Appear: NAACL-2015, (2011).<br>[5] Johnson, R., &amp; Zhang, T. (2015). Semi-supervised Convolutional Neural Networks for Text Categorization via Region Embedding.<br>[6] Wang, P., Xu, J., Xu, B., Liu, C., Zhang, H., Wang, F., &amp; Hao, H. (2015). Semantic Clustering and Convolutional Neural Network for Short Text Categorization. Proceedings ACL 2015, 352–357.<br>[7] Zhang, Y., &amp; Wallace, B. (2015). A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification,<br>[8] Nguyen, T. H., &amp; Grishman, R. (2015). Relation Extraction: Perspective from Convolutional Neural Networks. Workshop on Vector Modeling for NLP, 39–48.<br>[9] Sun, Y., Lin, L., Tang, D., Yang, N., Ji, Z., &amp; Wang, X. (2015). Modeling Mention , Context and Entity with Neural Networks for Entity Disambiguation, (Ijcai), 1333–1339.<br>[10] Zeng, D., Liu, K., Lai, S., Zhou, G., &amp; Zhao, J. (2014). Relation Classification via Convolutional Deep Neural Network. Coling, (2011), 2335–2344.<br>[11] Gao, J., Pantel, P., Gamon, M., He, X., &amp; Deng, L. (2014). Modeling Interestingness with Deep Neural Networks.<br>[12] Shen, Y., He, X., Gao, J., Deng, L., &amp; Mesnil, G. (2014). A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval. Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management – CIKM ’14, 101–110.<br>[13] Weston, J., &amp; Adams, K. (2014). # T AG S PACE : Semantic Embeddings from Hashtags, 1822–1827.</p>
<p><a href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" target="_blank" rel="external">原文</a></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/posts/2015/11/03/Java多线程同步的五种方法/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">Java多线程同步的五种方法</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>




<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Understanding Convolutional Neural Networks for NLP" data-title="Understanding Convolutional Neural Networks for NLP" data-url="http://yoursite.com/posts/2015/11/08/Understanding Convolutional Neural Networks for NLP/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    	</div>
      <div class="footer-center" >
      &copy; 2015 Ola·火力全開
      </div>
    	<div class="footer-center">
    	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>